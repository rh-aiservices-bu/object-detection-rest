{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "In notebook [1_explore.ipynb](1_explore.ipynb) we saw how to use a pre-trained object detection model to identify objects in a static image. In this notebook, we consider which parts of the code we used are crucial in making a prediction, and remove the code which was merely used to explore the data.\n",
    "\n",
    "You might have noticed that this folder we are working in contains afew files we haven't talked about. This 'project' has been set up for us by our Super Star Application Developer, and contains everything we need to easily go from experiment to application.\n",
    "\n",
    "The process we will be using to create our application is called source-to-image, or s2i. Don't worry if you've never heard of it! We will step you through what you need to do! For now, take a look at the way in which the project is organised:\n",
    "\n",
    "### Project Organization\n",
    "```\n",
    ".\n",
    "├── README.md\n",
    "├── LICENSE\n",
    "├── requirements.txt        <- Used to install packages for s2i application\n",
    "├── 1_explore.ipynb         <- Notebook for data and use case exploration\n",
    "├── 2_predict.ipynb         <- Notebook for creating a predict function\n",
    "├── 3_run_flask.ipynb       <- Notebook for running flask locally to test\n",
    "├── 4_test_flask.ipynb      <- Notebook for testing flask requests\n",
    "├── .gitignore              <- standard python gitignore\n",
    "├── .s2i                    <- hidden folder for advanced s2i configuration\n",
    "│   └── environment         <- s2i environment settings\n",
    "├── gunicorn_config.py      <- configuration for gunicorn when run in OpenShift\n",
    "├── prediction.py           <- the predict function called from Flask\n",
    "└── wsgi.py                 <- basic Flask application\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "In the previous notebook, all of our libraries were already installed for us because we selected the 'tensorflow' notebook image from the Jupyterhub spawner. However, when we run the model as part of an application we need to ensure we are packaging the model with the correct requirements. Take a look at the `requirements.txt` file to see which libraries we need for our application.\n",
    "\n",
    "\n",
    "We can install these libraries into our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "KUu4vOt5zI9d"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a Predict Function\n",
    "\n",
    "Extract the prediction logic into a standalone function called `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "model_dir = 'models/openimages_v4_ssd_mobilenet_v2_1'\n",
    "saved_model = tf.saved_model.load(model_dir)\n",
    "detector = saved_model.signatures['default']\n",
    "\n",
    "\n",
    "def predict(body):\n",
    "    base64img = body.get('image')\n",
    "    img_bytes = base64.decodebytes(base64img.encode())\n",
    "    detections = detect(img_bytes)\n",
    "    cleaned = clean_detections(detections)\n",
    "\n",
    "    return { 'detections': cleaned }\n",
    "\n",
    "\n",
    "def detect(img):\n",
    "    image = tf.image.decode_jpeg(img, channels=3)\n",
    "    converted_img  = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
    "    result = detector(converted_img)\n",
    "    num_detections = len(result[\"detection_scores\"])\n",
    "\n",
    "    output_dict = {key:value.numpy().tolist() for key, value in result.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def clean_detections(detections):\n",
    "    cleaned = []\n",
    "    max_boxes = 10\n",
    "    num_detections = min(detections['num_detections'], max_boxes)\n",
    "\n",
    "    for i in range(0, num_detections):\n",
    "        d = {\n",
    "            'box': {\n",
    "                'yMin': detections['detection_boxes'][i][0],\n",
    "                'xMin': detections['detection_boxes'][i][1],\n",
    "                'yMax': detections['detection_boxes'][i][2],\n",
    "                'xMax': detections['detection_boxes'][i][3]\n",
    "            },\n",
    "            'class': detections['detection_class_entities'][i].decode('utf-8'),\n",
    "            'label': detections['detection_class_entities'][i].decode('utf-8'),\n",
    "            'score': detections['detection_scores'][i],\n",
    "        }\n",
    "        cleaned.append(d)\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing the Prediction Function\n",
    "\n",
    "Let's try our new `predict` function and make sure it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image file location.\n",
    "my_image = 'twodogs.jpg'\n",
    "\n",
    "with open(my_image, \"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "content = {\"image\": encoded_image}\n",
    "\n",
    "result = predict(content)\n",
    "result['detections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualizing the Results\n",
    "\n",
    "That JSON is a bit hard to read, let's take a look at what it would look like if we used that data to draw the boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "\n",
    "\n",
    "def display_image(image):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image)\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "               (left, top)], width=thickness, fill=color)\n",
    "\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                        (left + text_width, text_bottom)], fill=color)\n",
    "        draw.text((left + margin, text_bottom - text_height - margin),\n",
    "                  display_str, fill=\"black\", font=font)\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, detections):\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "    class_colors = {}\n",
    "    font = ImageFont.load_default()\n",
    "    image_pil = Image.open(image)\n",
    "\n",
    "    for d in detections:\n",
    "        display_str = \"{}: {}%\".format(d['class'], int(100 * d['score']))\n",
    "        if not class_colors.get(d['class']):\n",
    "            class_colors[d['class']] = colors[hash(d['class']) % len(colors)]\n",
    "        color = class_colors.get(d['class'])\n",
    "        draw_bounding_box_on_image(\n",
    "            image_pil,\n",
    "            d['box']['yMin'],\n",
    "            d['box']['xMin'],\n",
    "            d['box']['yMax'],\n",
    "            d['box']['xMax'],\n",
    "            color,\n",
    "            font,\n",
    "            display_str_list=[display_str])\n",
    "    return image_pil\n",
    "\n",
    "\n",
    "draw_boxes(my_image, result['detections'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Predict function into Python files\n",
    "\n",
    "Now that we've got a working function, extract the prediction logic into a standalone python file, `prediction.py` in a `predict` function.  Also, make sure `requirements.txt` is updated with any additional packages you've used and need for prediction.\n",
    "\n",
    "## Test the function from your Python file\n",
    "\n",
    "We can make sure the extraction worked properly by loading the function from our `prediction.py` file and testing it out to make sure it works the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction import predict\n",
    "\n",
    "#image file location.\n",
    "my_image = 'twodogs.jpg'\n",
    "\n",
    "with open(my_image, \"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "content = {\"image\": encoded_image}\n",
    "\n",
    "result = predict(content)\n",
    "print(result['detections'])\n",
    "draw_boxes(my_image, result['detections'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Object detection",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
